services:
  # PostgreSQL Database
  # NOTE: Database data is stored on external SSD for persistence
  # To migrate from Docker volume to SSD bind mount:
  # 1. docker compose down
  # 2. mkdir -p /Volumes/Imago/MHC-Control_Panel/db
  # 3. docker run --rm -v mhc-control-panel_postgres_data:/source -v /Volumes/Imago/MHC-Control_Panel/db:/target alpine cp -a /source/. /target/
  # 4. docker compose up -d
  db:
    image: postgres:15-alpine
    container_name: mhc-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: mhc_control_panel
      POSTGRES_USER: mhc_user
      POSTGRES_PASSWORD: mhc_password
    ports:
      - '5433:5432'
    volumes:
      # SSD bind mount for database persistence (migrated from postgres_data volume)
      - /Volumes/Imago/MHC-Control_Panel/db:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U mhc_user -d mhc_control_panel']
      interval: 10s
      timeout: 5s
      retries: 5

  # Backend Web Server
  web:
    image: refineo/mhc-web:latest
    build:
      context: .
      dockerfile: Dockerfile.web
    container_name: mhc-web
    restart: unless-stopped
    ports:
      - '3002:3002'
    environment:
      NODE_ENV: production
      RUN_MODE: web
      PORT: 3002
      DATABASE_URL: postgresql://mhc_user:mhc_password@db:5432/mhc_control_panel
      LOG_LEVEL: info
      # Set these in .env file - see .env.example
      CHATURBATE_USERNAME: ${CHATURBATE_USERNAME}
      CHATURBATE_STATS_TOKEN: ${CHATURBATE_STATS_TOKEN}
      CHATURBATE_EVENTS_TOKEN: ${CHATURBATE_EVENTS_TOKEN}
      STATBATE_API_TOKEN: ${STATBATE_API_TOKEN}
      STATBATE_PLUS_SESSION_COOKIE: ${STATBATE_PLUS_SESSION_COOKIE:-}
      STATBATE_PLUS_XSRF_TOKEN: ${STATBATE_PLUS_XSRF_TOKEN:-}
      # OpenAI for AI summaries
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4.1-mini}
      OPENAI_MAX_TOKENS: ${OPENAI_MAX_TOKENS:-6000}
      # AWS S3 for external storage (optional)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_REGION: ${AWS_REGION:-us-east-1}
    volumes:
      - browser_data:/app/data
      # SSD mount for local cache (S3 is primary storage)
      - /Volumes/Imago/MHC-Control_Panel/media:/mnt/ssd/mhc-images
    depends_on:
      db:
        condition: service_healthy
    command: sh -c "npm run migrate && npm start"

  # Background Worker for Events API
  worker:
    image: refineo/mhc-worker:latest
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: mhc-worker
    restart: unless-stopped
    environment:
      NODE_ENV: production
      RUN_MODE: worker
      DATABASE_URL: postgresql://mhc_user:mhc_password@db:5432/mhc_control_panel
      LOG_LEVEL: info
      # Set these in .env file - see .env.example
      CHATURBATE_USERNAME: ${CHATURBATE_USERNAME}
      CHATURBATE_EVENTS_TOKEN: ${CHATURBATE_EVENTS_TOKEN}
      # AWS S3 for external storage (optional)
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_REGION: ${AWS_REGION:-us-east-1}
    volumes:
      # SSD mount for local cache (S3 is primary storage)
      - /Volumes/Imago/MHC-Control_Panel/media:/mnt/ssd/mhc-images
    depends_on:
      db:
        condition: service_healthy
      web:
        condition: service_started

  # React Frontend
  frontend:
    image: refineo/mhc-frontend:latest
    build:
      context: ./client
      dockerfile: Dockerfile
      args:
        REACT_APP_API_URL: http://localhost:3002
    container_name: mhc-frontend
    restart: unless-stopped
    ports:
      - '8080:80'
    depends_on:
      - web

volumes:
  browser_data:
    driver: local
  # NOTE: image_data volume has been removed - S3 is now primary storage
  # Backup stored at /Volumes/Imago/MHC-Control_Panel/docker-images-backup/
